{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NPCA-TEAM/COVID-19/blob/main/Scripts/%206%20-%20AVALIA%C3%87%C3%83O_covid_ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDVRez9ivbXr"
      },
      "source": [
        "# Preparação do ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MFMNOiBNl8g"
      },
      "source": [
        "## Login Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLYZ0oe_9hRr"
      },
      "outputs": [],
      "source": [
        "#Inicia permitindo acesso ao Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOqc1PwSNp8X"
      },
      "source": [
        "## Instalações de dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHspQlh_vMUt"
      },
      "outputs": [],
      "source": [
        "!pip install darts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN_kqgcAFaDY"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib==3.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiH892NVvYkm"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml==5.4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Njl-HGNvD_"
      },
      "source": [
        "## Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.backends"
      ],
      "metadata": {
        "id": "Qg3yu6bNbNxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LocReGiHvr3Z"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import math\n",
        "\n",
        "import matplotlib.backends\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "from datetime import datetime\n",
        "from darts import timeseries\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.models import KalmanFilter\n",
        "\n",
        "from darts.metrics import mae, mse, mape, mase, smape, rmse, r2_score, coefficient_of_variation\n",
        "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis, plot_hist\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import logging\n",
        "logging.disable(logging.CRITICAL)\n",
        "torch.manual_seed(1); np.random.seed(1)  # for reproducibility\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "uhzuDDKGlMIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N29D5AklHsDl"
      },
      "source": [
        "# Codificação para a avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import timeit\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "nXMyNJmO2Z7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s82MhehLwT1m"
      },
      "outputs": [],
      "source": [
        "datetime.today().strftime(\"%d_%m_%Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção da classe para avaliação estatística e seleção do modelo (ajustar data na linha 8)"
      ],
      "metadata": {
        "id": "WylBIZcTmVPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j2JX-lpFxwf"
      },
      "outputs": [],
      "source": [
        "class ErrorModel:\n",
        "\n",
        "  def __init__(self, validation_or_train, sintoma_or_publicacao_or_ocorrencia, casos_obitos): # Inicialização\n",
        "    self.casos_obitos = casos_obitos\n",
        "    self.__validation_or_train = validation_or_train # Validação se é dados de validação ou treino\n",
        "    self.pathErrorTable = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/Errors' # Caminho dos erros\n",
        "    self.models = ['NHITS','NBEATS', 'TFT', 'TCN', 'TRANSFORMER'] # Modelos utilizados \n",
        "    self.date = '28_11_2022' # Data --> Modificar para data atual  = MODIFICAR SEMPRE ESSA DATA\n",
        "    self.sintoma_or_publicacao_or_ocorrencia = sintoma_or_publicacao_or_ocorrencia # Dados se forem de sintoma ou publicação\n",
        "    self.path_seletedModels = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/SelectedModel/' # Caminho dos modelos selecionados\n",
        "    self.TableError()\n",
        "# ========================================================================================\n",
        "# ------------------------------------- Setters ------------------------------------------\n",
        "# ========================================================================================\n",
        "  \n",
        "  \n",
        "\n",
        "  @property\n",
        "  def casos_or_obitos_folder(self):\n",
        "    if self.casos_obitos == 'casos':\n",
        "      self.casos_or_obitos = '_CASOS'\n",
        "    elif self.casos_obitos == 'obitos':\n",
        "      self.casos_or_obitos = '_OBITOS'\n",
        "   \n",
        "    return self.casos_or_obitos\n",
        "\n",
        "  @property\n",
        "  def sintoma_or_publicacao_or_ocorrencia_column(self):\n",
        "    if self.casos_obitos == 'casos':\n",
        "      if self.sintoma_or_publicacao_or_ocorrencia == 'sintoma': # Pegando os dados de sintoma ou publicação\n",
        "        column = 'DataSintoma'\n",
        "      elif self.sintoma_or_publicacao_or_ocorrencia == 'publicacao':\n",
        "        column = 'Publicacao'\n",
        "    elif self.casos_obitos == 'obitos': \n",
        "      if self.sintoma_or_publicacao_or_ocorrencia == 'ocorrencia': # Pegando os dados de sintoma ou publicação\n",
        "        column = 'DataOcorrencia'\n",
        "      elif self.sintoma_or_publicacao_or_ocorrencia == 'publicacao':\n",
        "        column = 'Publicacao'\n",
        "    return column\n",
        "\n",
        "  @property\n",
        "  def casos_obitos_column(self):\n",
        "    if self.casos_obitos == 'casos':\n",
        "      first = 'Casos'\n",
        "    elif self.casos_obitos == 'obitos':\n",
        "      first = 'Obitos'\n",
        "\n",
        "    return first\n",
        " \n",
        "\n",
        "  @property\n",
        "  def real_model(self): # Extraindo os dados reais\n",
        "    \n",
        "    path_dataset = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/DataSet/'  \n",
        "    file_list = glob.glob(path_dataset + '*')\n",
        "    file_path = max(file_list, key=os.path.getctime)\n",
        "\n",
        "    dataframe = pd.read_excel(file_path, sheet_name=0)\n",
        "    \n",
        "    dataframe = dataframe.loc[:, ['data', f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA']]\n",
        "\n",
        "    dataframe[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA'] = np.where(dataframe[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA'] <= 0, 0.00001, dataframe[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA'])\n",
        "    \n",
        "    t_s = timeseries.TimeSeries.from_dataframe(df=dataframe, time_col= 'data')\n",
        "    t_s = t_s.astype('float64')\n",
        "\n",
        "    return t_s\n",
        "    \n",
        "\n",
        "  @property\n",
        "  def read_and_process_models(self): # Leitura e processamento dos conjuntos de dados\n",
        "   \n",
        "    if self.__validation_or_train == 'train':\n",
        "      path_forecasts = \"training_Forecast.csv\"\n",
        "\n",
        "    elif self.__validation_or_train == 'validation':\n",
        "      path_forecasts = \"validation_Forecast.csv\"\n",
        "\n",
        "    path_NHITS = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/ForecastsOutputModel/NHITS-Model_{self.getDate}/{path_forecasts}'\n",
        "    path_NBEATS = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/ForecastsOutputModel/NBEATS-Model_{self.getDate}/{path_forecasts}'\n",
        "    path_TFT = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/ForecastsOutputModel/TFT-Model_{self.getDate}/{path_forecasts}'\n",
        "    path_TNC = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/ForecastsOutputModel/TCN-Model_{self.getDate}/{path_forecasts}'\n",
        "    path_Tranformer = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/ForecastsOutputModel/TRANSFORMER-Model_{self.getDate}/{path_forecasts}'\n",
        "\n",
        "    \n",
        "    # Cria DF\n",
        "    df_NHITS = pd.read_csv(path_NHITS)\n",
        "    df_NBEATS = pd.read_csv(path_NBEATS)\n",
        "    df_TFT = pd.read_csv(path_TFT)\n",
        "    df_TNC = pd.read_csv(path_TNC)\n",
        "    df_Tranformer = pd.read_csv(path_Tranformer)\n",
        "\n",
        "    # Pós Processamento\n",
        "    # Valores < 0 = 0\n",
        "\n",
        "    df_de_modelos =  [df_NHITS, df_NBEATS, df_TFT, df_TNC, df_Tranformer]\n",
        "\n",
        "    series_forecast = []\n",
        "\n",
        "    # Pega colunas Data e Casos de sintormas e publicação\n",
        "    \n",
        "    for i in df_de_modelos:\n",
        "      valForecasts = i.loc[:, ['data', f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA']]\n",
        "      valForecasts[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA'] = np.where(valForecasts[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA'] <= 0, 0.00001, valForecasts[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA'])\n",
        "\n",
        "      serie_valForecasts = timeseries.TimeSeries.from_dataframe(df=valForecasts,  time_col= 'data')\n",
        "      series_forecast.append(serie_valForecasts)\n",
        "      \n",
        "\n",
        "\n",
        "    return series_forecast\n",
        "\n",
        "\n",
        "# ========================================================================================\n",
        "# ----------------------------------- Getters --------------------------------------------\n",
        "# ========================================================================================\n",
        "\n",
        "  @property\n",
        "  def getSintomaPublicacao(self): # Get se os dados são de sintoma ou publicação\n",
        "    return self.sintoma_or_publicacao_or_ocorrencia\n",
        "  @property\n",
        "  def getValidationOrTrain(self): # Get se os dados são de validação ou treino\n",
        "    return self.__validation_or_train \n",
        "  @property\n",
        "  def getBestModel(self): # Get o melhor modelo do conjunto de dados\n",
        "    table_error = self.TableError()\n",
        "    return table_error.loc[table_error['NOTA_GERAL'] == table_error['NOTA_GERAL'].max()]['MODELO'].values[0]\n",
        "  @property\n",
        "  def getDate(self): # Get data dos dados (mesma para reais e forecast)\n",
        "    return self.date\n",
        "  \n",
        "  def getGlobalBestModelPath(self, n_models): # Get caminho do melhor modelo\n",
        "    bestmodels_g_path_r = []\n",
        "    bestmodels_g_path_e = []\n",
        "\n",
        "    for i in self.get_general_best_model(n_models)['Residuos']:\n",
        "      globalBestModelPath = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos}/Models/{i}-Model_{self.getDate}.pth.tar'\n",
        "      bestmodels_g_path_r.append(globalBestModelPath)\n",
        "    for i in self.get_general_best_model(n_models)['Erros']:\n",
        "      globalBestModelPath = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos}/Models/{i}-Model_{self.getDate}.pth.tar'\n",
        "      bestmodels_g_path_e.append(globalBestModelPath)\n",
        "\n",
        "    globalBestModelPath = {}\n",
        "    globalBestModelPath['Residuos'] = bestmodels_g_path_r\n",
        "    globalBestModelPath['Erros'] = bestmodels_g_path_e\n",
        "    globalBestModelPath['Score'] = list(range(len(bestmodels_g_path_e), 0, -1))\n",
        "    globalBestModelPath = pd.DataFrame(globalBestModelPath)\n",
        "\n",
        "    return globalBestModelPath\n",
        "\n",
        "\n",
        "# ========================================================================================\n",
        "# ----------------------------------- Tabela de erros ------------------------------------\n",
        "# ========================================================================================\n",
        "\n",
        "  def TableError(self): \n",
        "    values = []\n",
        "   \n",
        "    for j, k in zip(self.read_and_process_models, self.models): # Calculando erro caso os dados fonecidos sejam uma lista\n",
        "     \n",
        "      metric_mse = mse(self.real_model, j) \n",
        "      metric_mape = mape(self.real_model, j)  \n",
        "      metric_smape = smape(self.real_model, j) \n",
        "      metric_rmse = rmse(self.real_model, j) \n",
        "      #print(self.real_model[-8:])\n",
        "      #print(j)    \n",
        "      metric_r2_score = r2_score(self.real_model, j)  \n",
        "\n",
        "      if math.isnan (metric_r2_score) or math.isinf (metric_r2_score):\t\n",
        "        metric_r2_score = 0.0\n",
        "        #print('oi')\n",
        "      metric_coefficient_of_variation = coefficient_of_variation(self.real_model, j) \n",
        "      values.append([metric_mse, metric_mape, metric_smape, metric_rmse, metric_r2_score, metric_coefficient_of_variation, k.upper()]) \n",
        "\n",
        "\n",
        "    df = pd.DataFrame(columns = ['MSE', 'MAPE', 'SMAPE', 'RMSE', 'R2_SCORE', 'COEF_OF_VARIATION', 'MODELO']) # Criando df vazio para anexar notas\n",
        "\n",
        "    for i in values:\n",
        "      result = dict(zip(['MSE', 'MAPE', 'SMAPE', 'RMSE', 'R2_SCORE', 'COEF_OF_VARIATION', 'MODELO'], i)) # Criando dicionário com resultados\n",
        "      df_to_append = pd.DataFrame(result, index = [datetime.today().strftime(\"%d-%m-%Y\")]) # Criando DF com resultados\n",
        "      df = pd.concat([df, df_to_append]) \n",
        "      \n",
        "    tamanho = df.shape[0] # Buscando tamanho do dataframe para dar as notas \n",
        "    notas = np.linspace(0, 1, tamanho) # Definindo a maior nota como 1, menor 0 e o espaçamento dependete da quantidade de registros\n",
        "    new_df = df[['MODELO']]\n",
        "    new_df = new_df.sort_values(by = 'MODELO', ascending = True) # Criando dataframe somente com o nome dos modelos\n",
        "    metricas_df = df[['MODELO']].sort_values(by = 'MODELO', ascending = True) # Criando dataframe somente com o nome dos modelos\n",
        "    \n",
        "\n",
        "    for i in df.columns:     \n",
        "      if i in ['MSE', 'MAPE', 'SMAPE', 'RMSE', 'COEF_OF_VARIATION']: # Quanto menor, melhor\n",
        "        df[[i, 'MODELO']] = df[[i, 'MODELO']].sort_values(by= i, ascending = False)\n",
        "        metricas_df = metricas_df.merge(df[[i, 'MODELO']] , on = ['MODELO'])\n",
        "        df[i] = notas\n",
        "        new_df = new_df.merge(df[[i, 'MODELO']], how = 'inner', on = ['MODELO'])\n",
        "\n",
        "        # Juntando Serie de notas e utilizando o nome do modelo, para atribuir corretamente\n",
        "      elif i == 'MODELO': # Ignorar a coluna MODELO\n",
        "        continue \n",
        "      elif i in ['R2_SCORE']: # Quanto maior, melhor - VERIFICAR \n",
        "        df[[i, 'MODELO']] = df[[i, 'MODELO']].sort_values(by= i, ascending = True)\n",
        "        metricas_df = metricas_df.merge(df[[i, 'MODELO']] , on = ['MODELO'])\n",
        "        df[i] = notas\n",
        "        new_df = new_df.merge(df[[i, 'MODELO']], how = 'inner', on = ['MODELO'])\n",
        "\n",
        "    new_df['NOTA_GERAL'] = new_df[['MSE', 'MAPE', 'SMAPE', 'R2_SCORE', 'COEF_OF_VARIATION']].sum(axis=1, numeric_only=True) # Extraindo a soma das notas fornecidas\n",
        "    metricas_df = metricas_df.sort_values(by= 'MODELO', ascending = True)\n",
        "    new_df = new_df.sort_values(by= 'MODELO', ascending = True)\n",
        "    metricas_df['NOTA_GERAL'] = new_df['NOTA_GERAL']\n",
        "\n",
        "    return metricas_df\n",
        "\n",
        "# ========================================================================================\n",
        "# -------------------------------- Getters com argumentos --------------------------------\n",
        "# ----------------------------------- Tabela de erros ------------------------------------\n",
        "# ========================================================================================\n",
        "\n",
        "\n",
        "  def getSeriesReais(self, format): # Extraindo dados reais -- Retorna em DataFrame do Pandas ou em timeseries do darts\n",
        "    if format == 'dataframe':\n",
        "      return self.real_model.pd_dataframe()\n",
        "    elif format == 'timeseries':\n",
        "      return self.real_model\n",
        "\n",
        "    \n",
        "  def getSeriesForecast(self, format): # Extraindo dados forecast -- Retorna em DataFrame do Pandas ou em timeseries do darts\n",
        "    if format not in ['dataframe', 'timeseries']:\n",
        "      raise TypeError('Os formatos suportados são dataframe ou timeseries, em vez disso foi passado {}'.format(format))\n",
        "    elif format == 'dataframe':\n",
        "      dataframes = []\n",
        "      for i in self.read_and_process_models:\n",
        "        dataframe = i.pd_dataframe()\n",
        "        dataframes.append(dataframe)\n",
        "      return dict(zip(self.models, dataframes))\n",
        "    elif format == 'timeseries':\n",
        "      self.read_and_process_models\n",
        "\n",
        "\n",
        "# ========================================================================================\n",
        "# --------------------------------------- Funções ----------------------------------------\n",
        "# ----------------------------------- Tabela de erros ------------------------------------\n",
        "# ========================================================================================\n",
        "\n",
        "\n",
        "  def showErrorTable(self): # Mostra tabela de erros\n",
        "    return self.TableError()\n",
        "\n",
        "  def get_n_BestModel_errors(self, n): # Extraindo o n melhores modelos \n",
        "    table_error = self.TableError()\n",
        "    if n > len(table_error['MODELO'].values[:n]) +1: # Caso o argumento seja maior que a quantidade de dados\n",
        "      raise IndexError('O valor é maior que o conjunto de dados')\n",
        "    else:\n",
        "      return table_error.sort_values(by='NOTA_GERAL', ascending=False)['MODELO'].values[:n]\n",
        "\n",
        "  def saveBestModelPath(self, n): # Salvando tabela com o melhor modelo.\n",
        "    path = f'{self.pathErrorTable}/PathBestModels/PathBestModels_{self.getValidationOrTrain}_{self.getSintomaPublicacao}_{self.getDate}.csv'\n",
        "    self.getGlobalBestModelPath(n).to_csv(path, index = False)\n",
        "    print('Best Models Table saved at:\\t {}'.format(path))\n",
        "    return path\n",
        "\n",
        "  def saveErrorTable(self): # Salvando tabela de erros\n",
        "    \n",
        "    path = f'{self.pathErrorTable}/ErrorsTable/ErrorTable_{self.getValidationOrTrain}_{self.getSintomaPublicacao}_{self.getDate}.csv'\n",
        "    self.TableError().to_csv(path, index = False)\n",
        "    print(f'Error Table saved at:\\t{path}')\n",
        "    return path\n",
        "\n",
        "  def saveAll(self, n): # Salvando tudo.\n",
        "    self.saveBestModelPath(n)\n",
        "    self.saveErrorTable()\n",
        "    self.saveResiduos()\n",
        "    # self.saveAllFigures(n)\n",
        "\n",
        "# ========================================================================================\n",
        "# --------------------------------------- Funções ----------------------------------------\n",
        "# --------------------------------------- Residuos ---------------------------------------\n",
        "# ========================================================================================\n",
        " \n",
        "  def gerarResiduos(self): # Gerando dicionário com os resíduos\n",
        "    dict_residuos = {}\n",
        "    for i, j in  self.getSeriesForecast(format='dataframe').items():\n",
        "      residuos = self.getSeriesForecast(format='dataframe')[i].merge(self.getSeriesReais(format = 'dataframe'), 'inner', on ='data')\n",
        "      residuos = residuos[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA_y'] - residuos[f'{self.casos_obitos_column}_{self.sintoma_or_publicacao_or_ocorrencia_column}_MM_atual_PA_x']\n",
        "\n",
        "      dict_residuos[i] = residuos\n",
        "\n",
        "    \n",
        "    return pd.DataFrame(dict_residuos)\n",
        "\n",
        "  def plotResiduos(self, n_best_models=None):\n",
        "    figs = []\n",
        "    models = []\n",
        "    if n_best_models == None:\n",
        "      n_best_models = 5\n",
        "    best_models = self.get_n_BestModel_errors(n_best_models)\n",
        "    for i in best_models:\n",
        "      fig, ax = plt.subplots(2,2,figsize=(16,12))\n",
        "      fig.suptitle(f'{i}\\n{self.casos_obitos}, {self.sintoma_or_publicacao_or_ocorrencia}, {self.getValidationOrTrain}\\n{self.getDate}\\n\\n')\n",
        "      residuos = self.gerarResiduos()[i]\n",
        "      ax_l = qqplot(residuos, ax =ax[1][1], line = 's')\n",
        "      #plt.text(-0.35, 3500, 'QQ Plot', fontdict={'size':12})\n",
        "      ax_d = sns.distplot(residuos,ax=ax[0][1], bins =7)\n",
        "      ax_d.set_ylabel('Values')\n",
        "      ax_d.set_title('Distribution')\n",
        "      ax_d.set_xlabel('Count')\n",
        "      ax_acf = plot_acf(residuos, ax=ax[1][0], title = 'AutoCorrelation Function (ACF)')\n",
        "      font ={'weight':'bold'}\n",
        "      #plt.text(-8,-2100, 'Lag', fontdict = font)\n",
        "      #plt.text(-11.49,1000, 'ACF Value', fontdict = font, rotation = 90)\n",
        "      x = list(range(0,len(residuos)))\n",
        "      ax_reg = sns.regplot(x,residuos,label = 'Best-fit line',scatter_kws={\"s\": 10}, ax = ax[0][0], line_kws={'color':'red'})\n",
        "      new_x = list(self.gerarResiduos().index.astype('str'))\n",
        "      ax_reg.set_xticks(x, new_x)\n",
        "      ax_reg.set_title('Residual Values')\n",
        "      ax_reg.set_xlabel('Date')\n",
        "      ax_reg.set_ylabel('Residual values')\n",
        "      plt.show()\n",
        "\n",
        "      print('-------------------------')\n",
        "      fig.savefig(f'/content/drive/MyDrive/NPCA - COVID/PlotsTemp/{str(datetime.now())}.png')#deletar depois de ajustado\n",
        "      print('-------------------------')\n",
        "      figs.append(fig)\n",
        "      models.append(i)\n",
        "    models = dict(zip(models, figs))\n",
        "    return models\n",
        "  \n",
        "  def saveAllFigures(self, n):\n",
        "    ax = self.plotResiduos(n)\n",
        "    for model in ax:\n",
        "      ax[model].savefig(f'{self.pathErrorTable}/Residuos/Plots/Plot-{model}_{self.getSintomaPublicacao}_{self.getDate}.png')\n",
        "  \n",
        "  def saveFigure(self, model):\n",
        "    ax = self.plotResiduos(5)\n",
        "    ax[model].savefig(f'{self.pathErrorTable}/Residuos/Plots/Plot-{model}_{self.getSintomaPublicacao}_{self.getValidationOrTrain}_{self.getDate}.png');\n",
        "\n",
        "  def showResiduosInfo(self):\n",
        "    columns = ['COEF_ANGULAR', 'MEAN', 'STD', 'MODELO']\n",
        "    df = pd.DataFrame(columns = columns)\n",
        "    for i in self.models:\n",
        "      residuos = self.gerarResiduos()[i]\n",
        "      x = list(range(0,len(residuos)))\n",
        "      reg_model = sm.OLS(residuos, x).fit()\n",
        "\n",
        "      coef_angular = reg_model.params.x1\n",
        "      mean = residuos.mean()\n",
        "      std = residuos.std()\n",
        "\n",
        "      df2 = pd.DataFrame(dict(zip(columns, [coef_angular, mean, std, i])), index = [i])\n",
        "      df = pd.concat([df, df2])\n",
        "    notas = np.linspace(0, 1, df.shape[0])\n",
        "    df['NOTA_GERAL'] = 0\n",
        "    for i in  ['COEF_ANGULAR', 'MEAN', 'STD']:\n",
        "      df_new = df[['MODELO', i]]\n",
        "      df_new[i] = abs(df_new[i])\n",
        "      df_new = df_new.sort_values(by= i, ascending = False)\n",
        "      df = df.sort_values(by= i, ascending = False)\n",
        "      df_new[i] = notas\n",
        "      df['NOTA_GERAL'] = df['NOTA_GERAL'] + df_new[i]\n",
        "    df = df[['MODELO', 'COEF_ANGULAR', 'MEAN', 'STD', 'NOTA_GERAL']]\n",
        "    df = df.reset_index(drop = True)\n",
        "    return df\n",
        "\n",
        "  def get_n_Best_Residuos(self, n):\n",
        "    best_residuos = self.showResiduosInfo().sort_values(by='NOTA_GERAL', ascending=False)['MODELO'].values[:n]\n",
        "    return best_residuos\n",
        "\n",
        "  def saveResiduos(self):\n",
        "    path = f'{self.pathErrorTable}/Residuos/Tables/ResiduoInfo_{self.getValidationOrTrain}_{self.getSintomaPublicacao}_{self.getDate}.csv'\n",
        "    self.showResiduosInfo().to_csv(path, index = False)\n",
        "    print(f'Residual table saved at: {path}')\n",
        "# ========================================================================================\n",
        "# --------------------------------------- Funções ----------------------------------------\n",
        "# ---------------------------------- Residuos & Erros ------------------------------------\n",
        "# ========================================================================================\n",
        "\n",
        "  def get_general_best_model(self, n, format='dict'):\n",
        "    a = self.get_n_Best_Residuos(n)\n",
        "    b = self.get_n_BestModel_errors(n)\n",
        "\n",
        "    if format == 'dict':\n",
        "      best_G_model = {'Residuos':a, 'Erros':b}\n",
        "      return best_G_model\n",
        "    elif format == 'list':\n",
        "      a = list(a)\n",
        "      b = list(b)\n",
        "      for i in b:\n",
        "        a.append(i)\n",
        "      return a\n",
        "  \n",
        "\n",
        "  def compare_with(self, other_model, save_best_path = False, save_plot = False):\n",
        "    dict_best = {}\n",
        "    model_a = self.get_general_best_model(2, format = 'list')\n",
        "    model_b = other_model.get_general_best_model(2, format = 'list')\n",
        "    for i in model_b:\n",
        "      model_a.append(i)\n",
        "    for i in model_a:\n",
        "      dict_best[i] = model_a.count(i)\n",
        "    \n",
        "    if save_best_path:\n",
        "      columns = ['model', 'path', 'data']\n",
        "      best_compare_model = f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/Models/{max(dict_best, key=dict_best.get)}-Model_{self.getDate}.pth.tar'\n",
        "      pd.DataFrame(dict(zip(columns, [max(dict_best, key=dict_best.get), best_compare_model, self.getDate])),index= [0]).to_csv(f'/content/drive/MyDrive/NPCA - COVID/{self.casos_or_obitos_folder}/SelectedModel/PathBestModels_{self.sintoma_or_publicacao_or_ocorrencia}_{self.getDate}.csv', index= False)\n",
        "    if save_plot:\n",
        "      print(dict_best)\n",
        "      self.saveFigure(max(dict_best, key=dict_best.get))\n",
        "    return dict_best"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ErrorModel('train', 'sintoma', 'casos').gerarResiduos().index[800]"
      ],
      "metadata": {
        "id": "_DwcfrY3Tq32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ErrorModel('train', 'sintoma', 'casos').plotResiduos(1)"
      ],
      "metadata": {
        "id": "11GADQO-JREb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Avaliação dos modelos ajustados/treinados"
      ],
      "metadata": {
        "id": "aI0uRSTamh6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM6GgEwICvLu"
      },
      "outputs": [],
      "source": [
        "errosSintoma_TRAIN_CASOS = ErrorModel('train', 'sintoma', 'casos')\n",
        "errosSintoma_VAL_CASOS = ErrorModel('validation', 'sintoma', 'casos')\n",
        "\n",
        "errosSintoma_TRAIN_CASOS.saveAll(5)\n",
        "errosSintoma_VAL_CASOS.saveAll(5)\n",
        "\n",
        "errosSintoma_VAL_CASOS.compare_with(errosSintoma_TRAIN_CASOS, True, True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_TRAIN_CASOS =  ErrorModel('train', 'publicacao', 'casos')\n",
        "errosPublicacao_VAL_CASOS =  ErrorModel('validation', 'publicacao', 'casos')\n",
        "\n",
        "errosPublicacao_TRAIN_CASOS.saveAll(5)\n",
        "errosPublicacao_VAL_CASOS.saveAll(5)\n",
        "\n",
        "errosPublicacao_TRAIN_CASOS.compare_with(errosPublicacao_VAL_CASOS, True, True)"
      ],
      "metadata": {
        "id": "8XFPUNNC9EQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_TRAIN_OBITOS =  ErrorModel('train', 'publicacao', 'obitos')\n",
        "errosPublicacao_VAL_OBITOS =  ErrorModel('validation', 'publicacao', 'obitos')\n",
        "\n",
        "errosPublicacao_TRAIN_OBITOS.saveAll(5)\n",
        "errosPublicacao_VAL_OBITOS.saveAll(5)\n",
        "\n",
        "errosPublicacao_TRAIN_OBITOS.compare_with(errosPublicacao_VAL_OBITOS, True, True)"
      ],
      "metadata": {
        "id": "FmKP0-DUVYdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosOcorrencia_TRAIN_OBITOS =  ErrorModel('train', 'ocorrencia', 'obitos')\n",
        "errosOcorrencia_VAL_OBITOS =  ErrorModel('validation', 'ocorrencia', 'obitos')\n",
        "\n",
        "errosOcorrencia_TRAIN_OBITOS.saveAll(5)\n",
        "errosOcorrencia_VAL_OBITOS.saveAll(5)\n",
        "\n",
        "errosOcorrencia_TRAIN_OBITOS.compare_with(errosOcorrencia_VAL_OBITOS, True, True)"
      ],
      "metadata": {
        "id": "MiVux_dEDx3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSEm7hqpIH89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plots"
      ],
      "metadata": {
        "id": "8RpvbJfuWJIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Casos"
      ],
      "metadata": {
        "id": "w8DeJY9GWcoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de sitomas de treinamento para casos"
      ],
      "metadata": {
        "id": "KnawXW7AVebZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosSintoma_TRAIN_CASOS.plotResiduos()"
      ],
      "metadata": {
        "id": "swh2kqTnVStV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de sitomas de validação para casos"
      ],
      "metadata": {
        "id": "eBiCoSC0Vx1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosSintoma_VAL_CASOS.plotResiduos()"
      ],
      "metadata": {
        "id": "8o_5weSTV03Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de publicação de treinamento para casos"
      ],
      "metadata": {
        "id": "Tmyr7VU5WOwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_TRAIN_CASOS.plotResiduos()"
      ],
      "metadata": {
        "id": "8CaNtIoSWMfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de publicação de validação para casos"
      ],
      "metadata": {
        "id": "6c8VFVgqWugZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_VAL_CASOS.plotResiduos()"
      ],
      "metadata": {
        "id": "ISQWtZGWWrm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obitos"
      ],
      "metadata": {
        "id": "eYZXoun8XAA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de publicação de treinamento para obitos"
      ],
      "metadata": {
        "id": "7IRyoJ5gXO9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_TRAIN_OBITOS.plotResiduos()"
      ],
      "metadata": {
        "id": "d1mOQmCzXj60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de publicação de validação para obitos"
      ],
      "metadata": {
        "id": "JmuIOiNFXS-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_VAL_OBITOS.plotResiduos()"
      ],
      "metadata": {
        "id": "mZDWLXlNXkW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de ocorrência de treinamento para obitos"
      ],
      "metadata": {
        "id": "SpGXCQgQXS1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosOcorrencia_TRAIN_OBITOS.plotResiduos()"
      ],
      "metadata": {
        "id": "kCMOzNcHXkp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot de resíduos de ocorrência de validação para obitos"
      ],
      "metadata": {
        "id": "lROYD6jOXSnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosOcorrencia_VAL_OBITOS.plotResiduos()"
      ],
      "metadata": {
        "id": "EkJU4kKgXlGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tabelas de erros"
      ],
      "metadata": {
        "id": "rJNxzocHu9Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errosOcorrencia_TRAIN_OBITOS.showErrorTable()"
      ],
      "metadata": {
        "id": "0lpSHthXV1xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosOcorrencia_VAL_OBITOS.showErrorTable()"
      ],
      "metadata": {
        "id": "l4Ny_OWuvDzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_VAL_OBITOS.showErrorTable()"
      ],
      "metadata": {
        "id": "W9qtaXT1vDq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_TRAIN_OBITOS.showErrorTable()"
      ],
      "metadata": {
        "id": "-f621GMTvDfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_VAL_CASOS.showErrorTable()"
      ],
      "metadata": {
        "id": "Rm_O_5j2vDV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosPublicacao_TRAIN_CASOS.showErrorTable()"
      ],
      "metadata": {
        "id": "lY3vFDWrvDH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosSintoma_TRAIN_CASOS.showErrorTable()"
      ],
      "metadata": {
        "id": "GthTKyWvvJp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errosSintoma_VAL_CASOS.showErrorTable()"
      ],
      "metadata": {
        "id": "EmmO5vmLvKeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tabela de Resíduos"
      ],
      "metadata": {
        "id": "aRFkI4UM1l8A"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5MFMNOiBNl8g",
        "AOqc1PwSNp8X",
        "C2Njl-HGNvD_",
        "eBiCoSC0Vx1J",
        "Tmyr7VU5WOwD",
        "6c8VFVgqWugZ",
        "eYZXoun8XAA9",
        "7IRyoJ5gXO9C",
        "JmuIOiNFXS-2",
        "SpGXCQgQXS1z",
        "rJNxzocHu9Nt"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}